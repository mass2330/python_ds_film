{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Analyse de sentiments sur les critiques spectateurs sur Allociné**\n",
    "**Projet Python pour la Data science - 2A ENSAE**\n",
    "\n",
    "Zakaria BOULLIAIRE, Massyle DENDENE, Brian RAMESH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'idée de ce projet est de prédire (\"mettre la variable à prédire\"), à partir d'une analyse de sentiment faite sur les critiques données pas les spectateurs (et non la presse), sur le site Allociné. \n",
    "Nous allons donc consituer une base de données de film, en scrappant le site Allociné et en utilisant l'API de The Movie Database (TMDB) pour compléter les données manquantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BeutifulSoup pour le scrapping\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "\n",
    "# Classique python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "\n",
    "from warnings import warn\n",
    "from time import sleep\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil import parser \n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecte des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapping sur Allociné"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord, nous allons restreindre notre base de données aux films américains des années 2010 à 2021. Cela constiuerait une base de données de 11 822 films (avant nettoyage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données qui peuvent nous être utiles sont les suivantes : Titre original du film, identifiant du film sur Allociné (qui nous sera utile pour récupérer les critiques plus tard), la note des spectateurs et celle de la presse, le nombre de critiques presse, le nombre de critiques spectateurs et le nombre de votes pour la notes (dans une seule et même variable, qu'on spérera lors du nettoyage), la date de sortie du film, le budget et le Box Office US. \n",
    "Nous avions également commencer à scrapper le N°Visa du film, qui est unique pour chaque film, en vue d'utiliser cette donnée pour la collecte sur TMDB, mais il y avait énormément de film pour lesquels cette donnée manquait. Nous avons décider de ne pas l'utiliser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'idée de la fonction ci dessous est de scrapper les données dont on a besoin à partir de l'url et du nombre de page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 5 µs, total: 9 µs\n",
      "Wall time: 13.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def scraping_film_allocine(base_url, nb_page):\n",
    "\n",
    "    # Liste ou on stock nos données\n",
    "    data = []\n",
    "    \n",
    "    # Variable de comptage pour voir l'évolution du scrapping, et détecter les eventuelles erreurs\n",
    "    i=0\n",
    "\n",
    "    # Boucle sur les pages\n",
    "    for page in range(1, nb_page+1): \n",
    "        url_page_ac = f\"{base_url}{page}\"\n",
    "\n",
    "        response_page_ac = requests.get(url_page_ac)\n",
    "\n",
    "        if response_page_ac.status_code == 200:\n",
    "            bs_page_ac = bs(response_page_ac.text, \"html.parser\")\n",
    "            films_page_ac = bs_page_ac.findAll(\"li\", attrs={'class': \"mdl\"})\n",
    "\n",
    "            for film_allocine in films_page_ac:\n",
    "                i+=1\n",
    "                try:\n",
    "                    \n",
    "                    # Id du film sur allo cine\n",
    "                    meta_title_link = film_allocine.find('a', class_='meta-title-link')\n",
    "\n",
    "                    if meta_title_link:\n",
    "                        href1 = meta_title_link.get('href')\n",
    "                        film_id = href1.split('=')[-1].split('.')[0]\n",
    "                    else:\n",
    "                        film_id = None\n",
    "\n",
    "\n",
    "                    # Scrapping de la page fiche info du film qu'on obtient grace à l'id trouvé ci dessus\n",
    "                    url_fiche_film = f'https://www.allocine.fr/film/fichefilm_gen_cfilm={film_id}.html'\n",
    "                    response_fiche_film = requests.get(url_fiche_film)\n",
    "                    bs_fiche_film = bs(response_fiche_film.text, \"html.parser\")\n",
    "\n",
    "                    # Titre\n",
    "                    titre_allocine = meta_title_link.text\n",
    "\n",
    "                    span_titre_original = bs_fiche_film.find('span', class_='light', string='Titre original ')\n",
    "                    titre_original = span_titre_original.find_next_sibling(string=True).strip() if span_titre_original else titre_allocine\n",
    "\n",
    "\n",
    "                    # Notes spectateurs/presse, nombre critiques presse/spectateurs\n",
    "                    bloc_notes = bs_fiche_film.findAll('span', class_='stareval-note')\n",
    "                    list_notes = [notes.get_text(strip=True) for notes in bloc_notes]\n",
    "\n",
    "                    if len(list_notes)==0:\n",
    "                        note_presse = None\n",
    "                        note_spectateur = None\n",
    "                        \n",
    "                    else:\n",
    "                        index_delimiteur = list_notes.index('--')\n",
    "                        new_liste_notes = list_notes[:index_delimiteur]\n",
    "\n",
    "                        if len(new_liste_notes)==2:\n",
    "                            note_presse = new_liste_notes[0]\n",
    "                            note_spectateur = new_liste_notes[1]\n",
    "                        \n",
    "                        elif len(new_liste_notes) > 0 and len(new_liste_notes) <= 1:\n",
    "                            note_spectateur = new_liste_notes[0]\n",
    "                            note_presse = None\n",
    "\n",
    "                    bloc_critiques = bs_fiche_film.find_all('span', class_='stareval-review')\n",
    "\n",
    "                    if len(bloc_critiques)==2:\n",
    "                        critiques_element_presse = bloc_critiques[0].text\n",
    "                        critiques_element_spec = bloc_critiques[1].text\n",
    "                    elif len(bloc_critiques) > 0 and len(bloc_critiques) <= 1:\n",
    "                        critiques_element_spec = bloc_critiques[0].text\n",
    "                        critiques_element_presse = None\n",
    "                    else:\n",
    "                        critiques_element_presse = None\n",
    "                        critiques_element_spec = None\n",
    "\n",
    "\n",
    "                    #Date, durée, budget\n",
    "                    date_film_element = film_allocine.find('span', class_='date')\n",
    "                    date_film = date_film_element.text if date_film_element else None\n",
    "\n",
    "                    duree_film_element = bs_fiche_film.find('span', class_='spacer')\n",
    "                    duree_film = duree_film_element.next_sibling.strip() if duree_film_element else None\n",
    "\n",
    "                    budget_element = bs_fiche_film.find('span', class_='what light', string='Budget')\n",
    "                    budget_film = budget_element.find_next('span').string if budget_element else None\n",
    "\n",
    "                    #visa_element = bs_fiche_film.find('span', class_='what light', string='N° de Visa')\n",
    "                    #visa_film = visa_element.find_next('span').string if visa_element else None\n",
    "\n",
    "                    # Box office\n",
    "                    url_box_office = f'https://www.allocine.fr/film/fichefilm-{film_id}/box-office/'\n",
    "                    response_box_office = requests.get(url_box_office)\n",
    "                    bs_box_office = bs(response_box_office.text, \"html.parser\")\n",
    "\n",
    "                    cumul = bs_box_office.findAll('td', {'data-heading': 'Cumul'})\n",
    "                    list_cumul = [cum.get_text(strip=True) for cum in cumul]\n",
    "\n",
    "                    box_office_film = list_cumul[-1] if list_cumul else 'None'\n",
    "\n",
    "                    data.append([titre_original, note_presse, note_spectateur, critiques_element_presse, critiques_element_spec, film_id, box_office_film, budget_film,\n",
    "                                date_film, duree_film])\n",
    "                    \n",
    "                    df_data = pd.DataFrame(data, columns=[\"Titre original\", \"Note press\", \"Notes spectateur\", \"Critiques presse\", \"Critiques spectateurs\", 'id allocine',\n",
    "                                          'Box office', 'Budget', 'date', 'duree'])\n",
    "\n",
    "\n",
    "                    print(i)\n",
    "                except Exception as e:\n",
    "                    print(f\"Une erreur s'est produite pour le film {i} : {e}\")\n",
    "\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Urls qu'on veut scrapper\n",
    "base_url_2010_2020, nb_page_2010_2020 = 'https://www.allocine.fr/films/pays-5002/decennie-2010/?page=', 646\n",
    "base_url_2020, nb_page_2020 = 'https://www.allocine.fr/films/pays-5002/decennie-2020/annee-2020/?page', 66\n",
    "base_url_2021, nb_page_2021 = 'https://www.allocine.fr/films/pays-5002/decennie-2020/annee-2021/?page', 77\n",
    "\n",
    "# Application de la fonction scrapping_film_allocine\n",
    "df_data_2010_2020 = scraping_film_allocine(base_url_2010_2020, nb_page_2010_2020)\n",
    "df_data_2020 = scraping_film_allocine(base_url_2020, nb_page_2020)\n",
    "df_data_2021 = scraping_film_allocine(base_url_2021, nb_page_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un DataFrame avec les données collectées\n",
    "dfs=[df_data_2010_2020, df_data_2020, df_data_2021]\n",
    "\n",
    "df_film_ac = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_film_ac.to_csv('df_film_ac.csv', index=False) ### DF important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nettoyage de la base obtenue sur Allociné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_film_ac= pd.read_csv(\"df_film_ac.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titre original</th>\n",
       "      <th>Note press</th>\n",
       "      <th>Notes spectateur</th>\n",
       "      <th>Critiques presse</th>\n",
       "      <th>Critiques spectateurs</th>\n",
       "      <th>id allocine</th>\n",
       "      <th>Box office</th>\n",
       "      <th>Budget</th>\n",
       "      <th>date</th>\n",
       "      <th>duree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shutter Island</td>\n",
       "      <td>3,8</td>\n",
       "      <td>4,4</td>\n",
       "      <td>31 critiques</td>\n",
       "      <td>80471 notes dont 4605 critiques</td>\n",
       "      <td>132039</td>\n",
       "      <td>127 770 000</td>\n",
       "      <td>80 000 000 $</td>\n",
       "      <td>24 février 2010</td>\n",
       "      <td>2h 17min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Inception</td>\n",
       "      <td>4,1</td>\n",
       "      <td>4,5</td>\n",
       "      <td>24 critiques</td>\n",
       "      <td>110095 notes dont 7212 critiques</td>\n",
       "      <td>143692</td>\n",
       "      <td>290 948 208</td>\n",
       "      <td>160 000 000 $</td>\n",
       "      <td>21 juillet 2010</td>\n",
       "      <td>2h 28min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Deathly Hallows - Part 1</td>\n",
       "      <td>3,2</td>\n",
       "      <td>4,0</td>\n",
       "      <td>20 critiques</td>\n",
       "      <td>52676 notes dont 2887 critiques</td>\n",
       "      <td>126693</td>\n",
       "      <td>291 377 000</td>\n",
       "      <td>150 000 000 $</td>\n",
       "      <td>24 novembre 2010</td>\n",
       "      <td>2h 26min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prince of Persia: The Sands of Time</td>\n",
       "      <td>2,6</td>\n",
       "      <td>3,1</td>\n",
       "      <td>22 critiques</td>\n",
       "      <td>26730 notes dont 2133 critiques</td>\n",
       "      <td>126678</td>\n",
       "      <td>89 981 000</td>\n",
       "      <td>200 000 000 $</td>\n",
       "      <td>26 mai 2010</td>\n",
       "      <td>2h 06min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Book of Eli</td>\n",
       "      <td>2,4</td>\n",
       "      <td>3,3</td>\n",
       "      <td>20 critiques</td>\n",
       "      <td>10503 notes dont 1144 critiques</td>\n",
       "      <td>128955</td>\n",
       "      <td>92 524 000</td>\n",
       "      <td>80 000 000 $</td>\n",
       "      <td>20 janvier 2010</td>\n",
       "      <td>1h 49min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11816</th>\n",
       "      <td>Amarillo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>294872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11817</th>\n",
       "      <td>Chastise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>295695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>Tapawingo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>296176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>Mr. Birthday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>298844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>A Kaddish for Bernie Madoff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>307242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11821 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Titre original Note press  \\\n",
       "0                                     Shutter Island        3,8   \n",
       "1                                          Inception        4,1   \n",
       "2      Harry Potter and the Deathly Hallows - Part 1        3,2   \n",
       "3                Prince of Persia: The Sands of Time        2,6   \n",
       "4                                    The Book of Eli        2,4   \n",
       "...                                              ...        ...   \n",
       "11816                                       Amarillo        NaN   \n",
       "11817                                       Chastise        NaN   \n",
       "11818                                      Tapawingo        NaN   \n",
       "11819                                   Mr. Birthday        NaN   \n",
       "11820                    A Kaddish for Bernie Madoff        NaN   \n",
       "\n",
       "      Notes spectateur Critiques presse              Critiques spectateurs  \\\n",
       "0                  4,4     31 critiques    80471 notes dont 4605 critiques   \n",
       "1                  4,5     24 critiques   110095 notes dont 7212 critiques   \n",
       "2                  4,0     20 critiques    52676 notes dont 2887 critiques   \n",
       "3                  3,1     22 critiques    26730 notes dont 2133 critiques   \n",
       "4                  3,3     20 critiques    10503 notes dont 1144 critiques   \n",
       "...                ...              ...                                ...   \n",
       "11816              NaN              NaN                                NaN   \n",
       "11817              NaN              NaN                                NaN   \n",
       "11818              NaN              NaN                                NaN   \n",
       "11819              NaN              NaN                                NaN   \n",
       "11820              NaN              NaN                                NaN   \n",
       "\n",
       "       id allocine   Box office         Budget              date     duree  \n",
       "0           132039  127 770 000   80 000 000 $   24 février 2010  2h 17min  \n",
       "1           143692  290 948 208  160 000 000 $   21 juillet 2010  2h 28min  \n",
       "2           126693  291 377 000  150 000 000 $  24 novembre 2010  2h 26min  \n",
       "3           126678   89 981 000  200 000 000 $       26 mai 2010  2h 06min  \n",
       "4           128955   92 524 000   80 000 000 $   20 janvier 2010  1h 49min  \n",
       "...            ...          ...            ...               ...       ...  \n",
       "11816       294872          NaN              -               NaN       NaN  \n",
       "11817       295695          NaN              -               NaN       NaN  \n",
       "11818       296176          NaN              -               NaN       NaN  \n",
       "11819       298844          NaN              -               NaN       NaN  \n",
       "11820       307242          NaN              -               NaN       NaN  \n",
       "\n",
       "[11821 rows x 10 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_film_ac "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut voir, la base a besoin d'être nettoyé. Nous allons extraires le nombre de critiques de la presse, le nombre de notes sepcteurs et le nombre de critiques des spectateurs. Nous allons convertir également le format de la date, et la durée du film en minute.\n",
    "\n",
    "Puis, nous allons supprimer tous les films qui n'ont pas de note spectateurs et/ou qui ont moins de 5 critiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titre original           object\n",
      "Note press               object\n",
      "Notes spectateur         object\n",
      "Critiques presse         object\n",
      "Critiques spectateurs    object\n",
      "id allocine               int64\n",
      "Box office               object\n",
      "Budget                   object\n",
      "date                     object\n",
      "duree                    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_film_ac.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifications des types \n",
    "\n",
    "df_film_ac['Box office'] = df_film_ac['Box office'].str.replace(' ', '').astype(float)\n",
    "df_film_ac['Note press'] = df_film_ac['Note press'].str.replace(',', '.').astype(float)\n",
    "df_film_ac['Notes spectateur'] = df_film_ac['Notes spectateur'].replace(\"--\", np.nan)\n",
    "df_film_ac['Notes spectateur'] = df_film_ac['Notes spectateur'].str.replace(',', '.').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titre original            object\n",
      "Note press               float64\n",
      "Notes spectateur         float64\n",
      "Critiques presse          object\n",
      "Critiques spectateurs     object\n",
      "id allocine                int64\n",
      "Box office               float64\n",
      "Budget                    object\n",
      "date                      object\n",
      "duree                     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_film_ac.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour convertir le mois en anglais\n",
    "def french_to_english_month(month_french):\n",
    "    months_mapping = {\n",
    "        'janvier': 'January',\n",
    "        'février': 'February',\n",
    "        'mars': 'March',\n",
    "        'avril': 'April',\n",
    "        'mai': 'May',\n",
    "        'juin': 'June',\n",
    "        'juillet': 'July',\n",
    "        'août': 'August',\n",
    "        'septembre': 'September',\n",
    "        'octobre': 'October',\n",
    "        'novembre': 'November',\n",
    "        'décembre': 'December'\n",
    "    }\n",
    "    return months_mapping.get(month_french.lower(), month_french)\n",
    "\n",
    "\n",
    "# Fonction pour convertir la durée en minutes\n",
    "def convert_duration(duration_str):\n",
    "    if isinstance(duration_str, str):\n",
    "        # Supprimer les espaces et diviser la chaîne en parties\n",
    "        parts = duration_str.replace(' ', '').split('h')\n",
    "\n",
    "        # Vérifier la présence des heures et des minutes\n",
    "        if len(parts) == 2:\n",
    "            hours = int(parts[0])\n",
    "            minutes = 0 if 'min' not in parts[1] else int(parts[1].replace('min', ''))\n",
    "            \n",
    "            # Calculer la durée totale en minutes\n",
    "            total_minutes = hours * 60 + minutes\n",
    "            \n",
    "            return int(total_minutes)\n",
    "    \n",
    "    # Gérer le cas où la valeur est déjà un nombre ou ne peut pas être convertie\n",
    "    return float('nan')\n",
    "\n",
    "\n",
    "\n",
    "# Fonction pouur extraire le nombre de critique de la presse \n",
    "def extract_critiques_count(critiques_str):\n",
    "    if isinstance(critiques_str, str):\n",
    "        # Utiliser isdigit() pour extraire uniquement les chiffres\n",
    "        return np.nan if not critiques_str.split()[0].isdigit() else int(critiques_str.split()[0])\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "\n",
    "# Fonction pour extraire le nombre de notes et le nombre de critiques\n",
    "def extract_notes_and_critiques_count(critiques_str):\n",
    "    if isinstance(critiques_str, str):\n",
    "        # Trouver les nombres dans la chaîne\n",
    "        numbers = [int(word) for word in critiques_str.split() if word.isdigit()]\n",
    "\n",
    "        # Extraire le nombre de notes et de critiques en fonction de la longueur de la liste \"numbers\"\n",
    "        if len(numbers) == 1:\n",
    "            return numbers[0], np.nan\n",
    "        elif len(numbers) == 2:\n",
    "            return numbers[0], numbers[1]\n",
    "\n",
    "    # Gérer le cas où la valeur est déjà un nombre ou ne peut pas être convertie\n",
    "    return np.nan, np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquons une série de fonction au datframe, pour plusieurs convertions, normalisations et extractions de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacer les chaînes \"nan\" par des valeurs NaN\n",
    "df_film_ac['date'] = df_film_ac['date'].replace('nan', np.nan)\n",
    "\n",
    "# Appliquer la fonction pour convertir le mois en anglais\n",
    "df_film_ac['date'] = df_film_ac['date'].apply(lambda x: ' '.join([french_to_english_month(word) for word in str(x).split()]) if pd.notna(x) else np.nan)\n",
    "\n",
    "# Utiliser dateutil.parser.parse pour convertir les dates en objets datetime\n",
    "df_film_ac['date'] = df_film_ac['date'].apply(lambda x: parser.parse(x, dayfirst=True) if isinstance(x, str) else x)\n",
    "\n",
    "# Appliquer la fonction de conversion pour la durée\n",
    "df_film_ac['duree_minutes'] = df_film_ac['duree'].apply(convert_duration)\n",
    "\n",
    "# Appliquer la fonction extract_notes_and_critiques_count\n",
    "df_film_ac[['Nombre_de_notes_spectateurs', 'Nombre_de_critiques_spectateurs']] = df_film_ac['Critiques spectateurs'].apply(extract_notes_and_critiques_count).apply(pd.Series)\n",
    "\n",
    "# Appliquer la fonction extract_critiques_count\n",
    "df_film_ac['Nombre_de_critiques_presse'] = df_film_ac['Critiques presse'].apply(extract_critiques_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrait des colonnes inutiles \n",
    "colonnes_a_retirer = [\"Critiques presse\",\"Critiques spectateurs\",\"duree\",\"Budget\"]\n",
    "df_film_ac = df_film_ac.drop(colonnes_a_retirer,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrait de tous les films sans critique spectateurs\n",
    "# On garde que les films avec au moins plus de 5 commentaires\n",
    "\n",
    "df_film_ac_clean = df_film_ac.dropna(subset=['Nombre_de_critiques_spectateurs'])\n",
    "df_film_ac_clean = df_film_ac_clean[df_film_ac_clean['Nombre_de_critiques_spectateurs'] >= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire le jour, le mois et l'année dans des colonnes distinctes\n",
    "df_film_ac_clean['mois_sortie'] = df_film_ac_clean['date'].dt.month\n",
    "df_film_ac_clean['annee_sortie'] = df_film_ac_clean['date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_film_ac_clean.to_csv('df_film_ac_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapping des données sur TMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le scrapping des données sur TMDB nécessite l'utilisation de l'API du site. Pour se faire, il a fallu créer une clé :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_api='d1d1413d8379729633d60e9f5cc4a730'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fonctions\n",
    "\n",
    "# Fonction pour récupérer l'id du film (à partir du titre du film issu de la base scrappé sur allociné)\n",
    "def id_recup(titre):\n",
    "    url_api=f\"https://api.themoviedb.org/3/search/movie?api_key={key_api}&query={titre}\" \n",
    "    req = requests.get(url_api)\n",
    "    carte = req.json()\n",
    "\n",
    "    ind=[]\n",
    "    for film in range(len(carte['results'])):\n",
    "        ind.append(carte['results'][film]['id'])\n",
    "    return(ind)\n",
    "\n",
    "\n",
    "# Fonction pour récuperer les infos du film à partir de l'id (prend en entrée l'id du film sur tmdb et renvoie un dataframe)\n",
    "def df_avec_id(id):\n",
    "    id_film= id\n",
    "    url_new_api = f\"https://api.themoviedb.org/3/movie/{id_film}?api_key={key_api}&language=en-US\"\n",
    "    req_new = requests.get(url_new_api)\n",
    "    wb_new = req_new.json()\n",
    "    \n",
    "    \n",
    "    #ajustement des données \n",
    "    if 'belongs_to_collection' in wb_new and wb_new['belongs_to_collection'] is not None:\n",
    "        wb_new['belongs_to_collection'] = wb_new['belongs_to_collection']['name']\n",
    "\n",
    "        \n",
    "    # Ajustement des données pour la clé 'genres'\n",
    "    if 'genres' in wb_new:\n",
    "        wb_new['genres'] = ', '.join([x['name'] for x in wb_new['genres']])\n",
    "    else:\n",
    "        wb_new['genres'] = None\n",
    "\n",
    "# Ajustement des données pour la clé 'production_companies'\n",
    "    if 'production_companies' in wb_new:\n",
    "        wb_new['production_companies'] = ', '.join([x['name'] for x in wb_new['production_companies']])\n",
    "    else:\n",
    "        wb_new['production_companies'] = None\n",
    "\n",
    "# Ajustement des données pour la clé 'production_countries'\n",
    "    if 'production_countries' in wb_new:\n",
    "        wb_new['production_countries'] = ', '.join([x['name'] for x in wb_new['production_countries']])\n",
    "    else:\n",
    "        wb_new['production_countries'] = None\n",
    "\n",
    "# Ajustement des données pour la clé 'spoken_languages'\n",
    "    if 'spoken_languages' in wb_new:\n",
    "        wb_new['spoken_languages'] = ', '.join([x['name'] for x in wb_new['spoken_languages']])\n",
    "    else:\n",
    "        wb_new['spoken_languages'] = None\n",
    "\n",
    "    \n",
    "    df=pd.DataFrame(wb_new, index=[0])\n",
    "    \n",
    "    return (df)\n",
    "\n",
    "\n",
    "def get_movie_info(movie_id_list):\n",
    "# Initialiser un DataFrame vide pour stocker les informations sur les films\n",
    "    movie_df = pd.DataFrame()\n",
    "\n",
    "    for movie_id in movie_id_list:\n",
    "        # Utiliser la deuxième fonction pour obtenir les informations détaillées du film\n",
    "        movie_info = df_avec_id(movie_id)\n",
    "\n",
    "        # Vérifier si des informations ont été trouvées\n",
    "        if movie_info is not None:\n",
    "            # Ajouter les informations du film au DataFrame\n",
    "            movie_df = pd.concat([movie_df, movie_info], ignore_index=True)\n",
    "\n",
    "    return movie_df\n",
    "\n",
    "\n",
    "def create_movie_list(movie_list):\n",
    "    all_movies_df = pd.DataFrame()\n",
    "\n",
    "    for movie_name in movie_list:\n",
    "        movie_id_list = id_recup(movie_name)\n",
    "        if movie_id_list:\n",
    "            movie_info_df = get_movie_info(movie_id_list)\n",
    "            # Ajouter les informations du film au DataFrame global\n",
    "            all_movies_df = pd.concat([all_movies_df, movie_info_df], ignore_index=True)\n",
    "\n",
    "    return all_movies_df\n",
    "\n",
    "\n",
    "\n",
    "# Fonction qui prend en entrée une liste et qui renvoie 4 sous-liste de taille identique (à une division entière près) \n",
    "def diviser_liste(liste):\n",
    "    taille = len(liste)\n",
    "    quart = taille // 4\n",
    "    partie1 = liste[:quart]\n",
    "    partie2 = liste[quart:2*quart]\n",
    "    partie3 = liste[2*quart:3*quart]\n",
    "    partie4 = liste[3*quart:]\n",
    "    return partie1, partie2, partie3, partie4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On récupère ensuite les films de la base d'Allociné nettoyé précédemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4194"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_film_ac_clean= pd.read_csv(\"df_film_ac_clean.csv\")\n",
    "liste_films_ac = df_film_ac_clean['Titre original'].tolist()\n",
    "\n",
    "len(liste_films_ac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va séparer notre dataframe en 4 en vue de la récolte des données à l'aide de l'API de TMDB. En effet, on rencontrait une erreur liée aux nombres de requêtes lorsqu'on utilisait le data frame en entier (ou même si on le séparait en 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partie 1: 1048\n",
      "Partie 2: 1048\n",
      "Partie 3: 1048\n",
      "Partie 4: 1050\n"
     ]
    }
   ],
   "source": [
    "liste_films_ac_1, liste_films_ac_2, liste_films_ac_3, liste_films_ac_4 = diviser_liste(liste_films_ac)\n",
    "\n",
    "\n",
    "# Affichage des quatres listes résultantes\n",
    "print(\"Partie 1:\", len(liste_films_ac_1))\n",
    "print(\"Partie 2:\", len(liste_films_ac_2))\n",
    "print(\"Partie 3:\", len(liste_films_ac_3))\n",
    "print(\"Partie 4:\", len(liste_films_ac_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "df_film_ac_clean_1 = create_movie_list(liste_films_ac_1)\n",
    "\n",
    "\n",
    "# CPU times: user 3min 37s, sys: 17.1 s, total: 3min 54s\n",
    "# Wall time: 21min 6s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_film_ac_clean_2 = create_movie_list(liste_films_ac_2)\n",
    "\n",
    "# CPU times: user 3min 54s, sys: 20.2 s, total: 4min 14s\n",
    "# Wall time: 21min 41s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_film_ac_clean_3 = create_movie_list(liste_films_ac_3)\n",
    "\n",
    "# CPU times: user 3min 52s, sys: 19.9 s, total: 4min 12s\n",
    "# Wall time: 20min 36s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_film_ac_clean_4 = create_movie_list(liste_films_ac_4)\n",
    "\n",
    "# CPU times: user 3min 43s, sys: 19.5 s, total: 4min 04s\n",
    "# Wall time: 20min 56s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rassembler les DataFrames en un seul DataFrame\n",
    "dataframes = [df_film_ac_clean_1, df_film_ac_clean_2, df_film_ac_clean_3, df_film_ac_clean_4]\n",
    "\n",
    "df_tmdb = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le DataFrame tmdb en CSV\n",
    "df_tmdb.to_csv('df_tmdb.csv', index=False)\n",
    "\n",
    "# Afficher le DataFrame final\n",
    "df_tmdb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage de la base TMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmdb= pd.read_csv(\"df_tmdb.csv\", engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult : 6\n",
      "backdrop_path : 15053\n",
      "belongs_to_collection : 30493\n",
      "budget : 181\n",
      "genres : 5489\n",
      "homepage : 26420\n",
      "id : 161\n",
      "imdb_id : 7521\n",
      "original_language : 181\n",
      "original_title : 161\n",
      "overview : 1692\n",
      "popularity : 187\n",
      "poster_path : 4893\n",
      "production_companies : 11739\n",
      "production_countries : 8237\n",
      "release_date : 2024\n",
      "revenue : 213\n",
      "runtime : 213\n",
      "spoken_languages : 7419\n",
      "status : 213\n",
      "tagline : 22747\n",
      "title : 213\n",
      "video : 213\n",
      "vote_average : 213\n",
      "vote_count : 213\n",
      "success : 34373\n",
      "status_code : 34373\n",
      "status_message : 34373\n"
     ]
    }
   ],
   "source": [
    "noms_variables = df_tmdb.columns.tolist()\n",
    "\n",
    "for i in noms_variables:\n",
    "    print(i,\":\",df_tmdb[i].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe que les trois dernières colonnes peuvent être supprimés de la dataframe car trop de valeurs manquantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colonnes_a_supprimer = [\"success\", \"status_code\", \"status_message\"]\n",
    "df_tmdb_clean = df_tmdb.drop(columns=colonnes_a_supprimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "release_date\n",
       "2009-01-01    75\n",
       "2011-01-01    71\n",
       "2008-01-01    70\n",
       "2014-01-01    68\n",
       "2007-01-01    68\n",
       "              ..\n",
       "2021-08-21     1\n",
       "1998-06-09     1\n",
       "1950-05-19     1\n",
       "1980-03-28     1\n",
       "1983-09-16     1\n",
       "Name: count, Length: 12586, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changement format release date \n",
    "\n",
    "df_tmdb_clean['release_date'] = pd.to_datetime(df_tmdb['release_date'], errors=\"coerce\")\n",
    "df_tmdb_clean[\"release_date\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire le jour, le mois et l'année dans des colonnes distinctes\n",
    "df_tmdb_clean['mois_sortie'] = df_tmdb_clean['release_date'].dt.month\n",
    "df_tmdb_clean['annee_sortie'] = df_tmdb_clean['release_date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge de la base Allociné et de la base TMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons procéder au merge des deux bases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par normalisé les titres en les mettant en minuscule, et en retirant les espace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_film_ac_clean= pd.read_csv(\"df_film_ac_clean.csv\", engine=\"python\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_film_ac_clean['titre_normalise'] = df_film_ac_clean['Titre original'].str.replace(r'\\W', '', regex=True).str.lower()\n",
    "df_tmdb_clean['titre_normalise'] = df_tmdb_clean['original_title'].str.replace(r'\\W', '', regex=True).str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par prendre les elements qui se ressemblent dans les deux listes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_titre_ac = df_film_ac_clean[\"titre_normalise\"].tolist()\n",
    "liste_titre_tmdb = df_tmdb_clean[\"titre_normalise\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_ressemblance = [element for element in liste_titre_tmdb if element in liste_titre_ac]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque à ce niveau que certains films apparaissent plusieurs fois dans liste_ressemblance du fait que de nombreux films sont sortis sous le meme nom "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On commence par garder dans la base df_tmdb_clean que les films qui sont dans liste_ressemblance\n",
    "df_filtre_tmdb = df_tmdb_clean[df_tmdb_clean['titre_normalise'].isin(liste_ressemblance)]\n",
    "\n",
    "\n",
    "# On trie ensuite la base par ordre alphabetique des films et decroissants des dates\n",
    "df_filtre_tmdb_trie = df_filtre_tmdb.sort_values(by=['titre_normalise', 'release_date'], ascending=[True, False])\n",
    "df_filtre_tmdb_trie = df_filtre_tmdb_trie.reset_index(drop=True)\n",
    "\n",
    "# Conservation des films sorties entre 2010 et 2021 (et valeurs manquantes aussi)\n",
    "df_filtre_tmdb_trie = df_filtre_tmdb_trie[(df_filtre_tmdb_trie['annee_sortie'] >= 2010) & (df_filtre_tmdb_trie['annee_sortie'] <= 2021) | df_filtre_tmdb_trie['annee_sortie'].isna()]\n",
    "df_filtre_tmdb_trie = df_filtre_tmdb_trie.reset_index(drop=True)\n",
    "\n",
    "# On retire tous les doublons parfaits de la base \n",
    "df_filtre_tmdb_trie = df_filtre_tmdb_trie.drop_duplicates(keep='first')\n",
    "df_filtre_tmdb_trie = df_filtre_tmdb_trie.reset_index(drop=True)\n",
    "\n",
    "df_filtre_tmdb_trie.to_csv(\"df_tmdb_tri.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour merge les deux bases, nous allons utiliser le nom du réalisateur comme clé primaire. En efft, étant donné, qu'il y a plusieurs fois le même titre sur la base de TMDB, il nous a fallu trouver une autre solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7312"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On recupere les id des films sur la base TMDB pour recuperer le nom des realisateur de chaque film\n",
    "liste_id = df_filtre_tmdb_trie[\"id\"].tolist()\n",
    "liste_id_entiers = [int(nombre) for nombre in liste_id]\n",
    "len(liste_id_entiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def get_directors_for_movies(movie_ids, api_key):\n",
    "    directors_dict = {}\n",
    "\n",
    "    for movie_id in movie_ids:\n",
    "        # Envoyer une requête GET à l'API TMDb pour obtenir les crédits du film\n",
    "        response = requests.get(f'https://api.themoviedb.org/3/movie/{movie_id}/credits?api_key={api_key}')\n",
    "\n",
    "        # Vérifier si la requête a réussi (code 200)\n",
    "        if response.status_code == 200:\n",
    "            # Extraire le contenu JSON de la réponse\n",
    "            json_data = response.json()\n",
    "\n",
    "            # Filtrer la liste des membres de l'équipe pour ne conserver que les réalisateurs\n",
    "            directors = [member.get('name') for member in json_data.get('crew', []) if member.get('job') == 'Director']\n",
    "\n",
    "            # Ajouter l'association identifiant-réalisateur au dictionnaire\n",
    "            directors_dict[movie_id] = directors if directors else None\n",
    "        else:\n",
    "            # En cas d'échec de la requête, ajouter une valeur manquante au dictionnaire\n",
    "            directors_dict[movie_id] = None\n",
    "\n",
    "    return directors_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"d1d1413d8379729633d60e9f5cc4a730\"\n",
    "\n",
    "# Appeler la fonction pour obtenir le dictionnaire des réalisateurs\n",
    "directors_result = get_directors_for_movies(liste_id_entiers, api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter une colonne 'nom_du_realisateur' en utilisant le dictionnaire\n",
    "df_filtre_tmdb_trie['nom_du_realisateur'] = df_filtre_tmdb_trie['id'].map(directors_result)\n",
    "\n",
    "# Afficher le DataFrame résultant\n",
    "df_filtre_tmdb_trie.head()\n",
    "df_filtre_tmdb_trie.to_csv(\"df_filtre_trie.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On récupère ensuite le nom des réalisateurs sur Allociné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 2 µs, total: 7 µs\n",
      "Wall time: 11.7 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def get_director_name(url):\n",
    "    # Envoyer une requête GET à l'URL de la page Allociné\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Vérifier si la requête a réussi (code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Extraire le contenu HTML de la réponse\n",
    "        html_content = response.content\n",
    "\n",
    "        # Utiliser BeautifulSoup pour parcourir le HTML\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Trouver la balise contenant le nom du réalisateur\n",
    "        director_tag = soup.find('div', class_='meta-body-direction')\n",
    "\n",
    "        # Extraire le texte entre les balises\n",
    "        director_name = director_tag.text.strip() if director_tag else None\n",
    "\n",
    "        return director_name\n",
    "\n",
    "    else:\n",
    "        # En cas d'échec de la requête, retourner une valeur manquante\n",
    "        return None\n",
    "\n",
    "def get_director_names_from_urls(identifiants):\n",
    "    director_names = {}\n",
    "\n",
    "    for identifiant in identifiants:\n",
    "        # Construire l'URL à partir de l'identifiant\n",
    "        url = f'https://www.allocine.fr/film/fichefilm_gen_cfilm={identifiant}.html'\n",
    "\n",
    "        # Appeler la fonction pour obtenir le nom du réalisateur\n",
    "        nom_realisateur = get_director_name(url)\n",
    "\n",
    "        # Ajouter le nom du réalisateur au dictionnaire\n",
    "        director_names[identifiant] = nom_realisateur\n",
    "\n",
    "    return director_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_identifiants = df_film_ac_clean[\"id allocine\"].tolist()\n",
    "\n",
    "resultat = get_director_names_from_urls(liste_identifiants)\n",
    "\n",
    "# Afficher le résultat\n",
    "#for identifiant, nom_realisateur in resultat.items():\n",
    "    #print(f\"Film {identifiant}: Réalisateur {nom_realisateur}\")\n",
    "\n",
    "print(len(resultat))\n",
    "print(resultat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter une colonne 'nom_du_realisateur' en utilisant le dictionnaire\n",
    "df_film_ac_clean['nom_du_realisateur'] = df_film_ac_clean['id allocine'].map(resultat)\n",
    "\n",
    "# Afficher le DataFrame résultant\n",
    "df_film_ac_clean.head()\n",
    "df_film_ac_clean.to_csv(\"df_film_ac_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_film_ac_clean['nom_du_realisateur'] = df_film_ac_clean['nom_du_realisateur'].str.replace('De\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ne pas mettre dans la meme cellule qu'avant\n",
    "\n",
    "df_film_ac_clean['nom_du_realisateur'] = df_film_ac_clean['nom_du_realisateur'].str.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtre_tmdb_trie['nom_du_realisateur'] = df_filtre_tmdb_trie['nom_du_realisateur'].apply(lambda x: x[0] if x else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prend en entrée un string et renvoie le même string sans les accents\n",
    "\n",
    "def remove_accents(input_str):\n",
    "    accents = {\n",
    "        'a': '[aáàâäãå]',\n",
    "        'e': '[eéèêë]',\n",
    "        'i': '[iíìîï]',\n",
    "        'o': '[oóòôöõ]',\n",
    "        'u': '[uúùûü]',\n",
    "        'c': '[cç]',\n",
    "        'n': '[nñ]'\n",
    "    }\n",
    "    for char, pattern in accents.items():\n",
    "        input_str = re.sub(pattern, char, input_str)\n",
    "    return input_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer la fonction remove_accents à la colonne nom_du_realisateur\n",
    "\n",
    "df_filtre_tmdb_trie['nom_du_realisateur_bis'] = df_filtre_tmdb_trie['nom_du_realisateur'].apply(lambda x: remove_accents(x) if pd.notnull(x) else x)\n",
    "df_film_ac_clean['nom_du_realisateur_bis'] = df_film_ac_clean['nom_du_realisateur'].apply(lambda x: remove_accents(x) if pd.notnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nnormalisation \n",
    "\n",
    "df_film_ac_clean['nom_du_realisateur_bis'] = df_film_ac_clean['nom_du_realisateur_bis'].str.replace(r'\\W', '', regex=True).str.lower()\n",
    "df_filtre_tmdb_trie['nom_du_realisateur_bis'] = df_filtre_tmdb_trie['nom_du_realisateur_bis'].str.replace(r'\\W', '', regex=True).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_film_ac_clean = df_film_ac_clean.sort_values(by=['titre_normalise', 'date'], ascending=[True, False])\n",
    "df_film_ac_clean = df_film_ac_clean.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conserve uniquement les correspondances\n",
    "df_merged = pd.merge(df_film_ac_clean, df_filtre_tmdb_trie, left_on=['titre_normalise', 'nom_du_realisateur_bis'], right_on=['titre_normalise', 'nom_du_realisateur_bis'])\n",
    "print(len(df_merged))\n",
    "\n",
    "df_merged.to_csv(\"df_merged.csv\", index=False)\n",
    "\n",
    "#conserve les correspondances et tout du cote df_film_avec_critiques\n",
    "#df_merged_bis= pd.merge(df_film_avec_critiques, df_filtre_trie, on=['titre_normalise', 'nom_du_realisateur_bis'], how='left')\n",
    "#df_merged_bis.to_csv(\"df_merged_bis.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapping des critiques sur Allocine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nous avons notre base finale, avec toutes les données, on peut faire le scrapping des critiques spectateurs sur Allociné grâce à l'id du film."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_ac = pd.read_csv('df_merged.csv')\n",
    "df_final_ac = df_final_ac.drop_duplicates(subset='id allocine', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784779\n"
     ]
    }
   ],
   "source": [
    "df_final_ac['Nombre_de_critiques_spectateurs'] = df_final_ac['Nombre_de_critiques_spectateurs'].astype(int)\n",
    "#df_final_ac = df_final_ac.sort_values(by='Nombre_de_critiques_spectateurs', ascending=False)\n",
    "\n",
    "somme_critique = df_final_ac['Nombre_de_critiques_spectateurs'].sum()\n",
    "\n",
    "liste_id = df_final_ac['id allocine'].tolist()\n",
    "nb_critique = df_final_ac['Nombre_de_critiques_spectateurs'].tolist()\n",
    "\n",
    "\n",
    "# Créez un dictionnaire à partir des couples\n",
    "couple_listes = zip(liste_id, nb_critique)\n",
    "dico_id_critique = dict(couple_listes)\n",
    "\n",
    "print(somme_critique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fonction qui prend en entrée un dictionnaire et un facteur. Renvoie une liste avec le dictionnaire découpé en ce nombre de facteur\n",
    "\n",
    "def divide_dict(dictionary, div):\n",
    "    if not isinstance(dictionary, dict):\n",
    "        raise ValueError(\"Le paramètre doit être un dictionnaire.\")\n",
    "\n",
    "    dict_items = list(dictionary.items())\n",
    "    total_items = len(dict_items)\n",
    "\n",
    "    if total_items % div != 0:\n",
    "        raise ValueError(\"Le dictionnaire ne peut pas être divisé en 8 parties égales.\")\n",
    "\n",
    "    chunk_size = total_items // div\n",
    "    divided_dicts = [dict_items[i:i + chunk_size] for i in range(0, total_items, chunk_size)]\n",
    "\n",
    "    return [dict(chunk) for chunk in divided_dicts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "divided_dicts = divide_dict(dico_id_critique, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_critique(film_id, page):\n",
    "    try:\n",
    "        base_url = f\"https://www.allocine.fr/film/fichefilm-{film_id}/critiques/spectateurs/?page=\"\n",
    "        url_page_critique = f\"{base_url}{page}\"\n",
    "        response_page_critique = requests.get(url_page_critique)\n",
    "\n",
    "        if response_page_critique.status_code == 200:\n",
    "            bs_page_critique = bs(response_page_critique.text, \"html.parser\")\n",
    "            films_page_critique = bs_page_critique.findAll(\"div\", attrs={'class': \"hred review-card cf\"})\n",
    "\n",
    "            critiques_data = []\n",
    "\n",
    "            for critique in films_page_critique:\n",
    "                note_critique = critique.find('span', class_='stareval-note').text.strip()\n",
    "                date_publication = critique.find('span', class_='review-card-meta-date light').text.strip()\n",
    "                critique_text = critique.find('div', class_='content-txt review-card-content').text.strip()\n",
    "\n",
    "                critiques_data.append([film_id, note_critique, date_publication, critique_text])\n",
    "\n",
    "            return critiques_data\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for movie {film_id}, page {page}: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def scraping_critique(dict_id_critique):\n",
    "    data = []\n",
    "    k = 0\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=100) as executor:  \n",
    "        futures = []\n",
    "\n",
    "        for film_id, nb_critique in dict_id_critique.items():\n",
    "            i = 0\n",
    "            page = 0\n",
    "\n",
    "            while i < nb_critique:\n",
    "                futures.append(executor.submit(scrape_critique, film_id, page))\n",
    "                page += 1\n",
    "                i += 15  \n",
    "\n",
    "        for future in futures:\n",
    "            critiques_data = future.result()\n",
    "            if critiques_data:\n",
    "                data.extend(critiques_data)\n",
    "                k += len(critiques_data)\n",
    "                print(f'Total: {k} / {sum(dict_id_critique.values())}')\n",
    "\n",
    "    df_critique = pd.DataFrame(data, columns=[\"id_allocine\", \"Note de la critique\", \"Date de publication\", 'Critique'])\n",
    "    return df_critique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "scrapping_critique_1 = scraping_critique(divided_dicts[0])\n",
    "scrapping_critique_1.to_csv('df_scrapping_critique_1.csv', index=False)\n",
    "\n",
    "# 47 / 47 critiques collected for movie 183831. Total : 54874 / 54825\n",
    "# CPU times: user 5min 44s, sys: 10 s, total: 5min 54s\n",
    "# Wall time: 34min 25s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "scrapping_critique_2 = scraping_critique(divided_dicts[1])\n",
    "scrapping_critique_2.to_csv('df_scrapping_critique_2.csv', index=False)\n",
    "\n",
    "# Total: 59834 / 58322\n",
    "# CPU times: user 8min 11s, sys: 21.8 s, total: 8min 33s\n",
    "# Wall time: 8min 32s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "scrapping_critique_3 = scraping_critique(divided_dicts[2])\n",
    "scrapping_critique_3.to_csv('df_scrapping_critique_3.csv', index=False)\n",
    "\n",
    "# Total: 71404 / 69577\n",
    "# CPU times: user 9min 41s, sys: 26.2 s, total: 10min 7s\n",
    "# Wall time: 10min 35s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "scrapping_critique_4 = scraping_critique(divided_dicts[3])\n",
    "scrapping_critique_4.to_csv('df_scrapping_critique_4.csv', index=False)\n",
    "\n",
    "# Total: 93462 / 91634\n",
    "# CPU times: user 13min 18s, sys: 36.4 s, total: 13min 55s\n",
    "# Wall time: 15min 35s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "scrapping_critique_5 = scraping_critique(divided_dicts[4])\n",
    "scrapping_critique_5.to_csv('df_scrapping_critique_5.csv', index=False)\n",
    "\n",
    "# Total: 80683 / 78722\n",
    "# CPU times: user 13min 25s, sys: 54 s, total: 14min 19s\n",
    "# Wall time: 12min 41s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "scrapping_critique_6 = scraping_critique(divided_dicts[5])\n",
    "scrapping_critique_6.to_csv('df_scrapping_critique_6.csv', index=False)\n",
    "\n",
    "# Total: 80772 / 78995\n",
    "# CPU times: user 13min 12s, sys: 56.2 s, total: 14min 9s\n",
    "# Wall time: 12min 55s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "scrapping_critique_7 = scraping_critique(divided_dicts[6])\n",
    "scrapping_critique_7.to_csv('df_scrapping_critique_7.csv', index=False)\n",
    "\n",
    "# Total: 93344 / 91573\n",
    "# CPU times: user 13min 1s, sys: 42.2 s, total: 13min 43s\n",
    "# Wall time: 15min 24s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "scrapping_critique_8 = scraping_critique(divided_dicts[7])\n",
    "scrapping_critique_8.to_csv('df_scrapping_critique_8.csv', index=False)\n",
    "\n",
    "# Total: 88212 / 86236\n",
    "# CPU times: user 12min 37s, sys: 44.6 s, total: 13min 22s\n",
    "# Wall time: 14min 20s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "scrapping_critique_9 = scraping_critique(divided_dicts[8])\n",
    "scrapping_critique_9.to_csv('df_scrapping_critique_9.csv', index=False)\n",
    "\n",
    "# Total: 84698 / 82657\n",
    "# CPU times: user 12min 13s, sys: 42.3 s, total: 12min 55s\n",
    "# Wall time: 13min 53s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "scrapping_critique_10 = scraping_critique(divided_dicts[9])\n",
    "scrapping_critique_10.to_csv('df_scrapping_critique_10.csv', index=False)\n",
    "\n",
    "# Total: 84698 / 82657\n",
    "# CPU times: user 12min 13s, sys: 42.3 s, total: 12min 55s\n",
    "# Wall time: 13min 53s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rassembler les DataFrames en un seul DataFrame\n",
    "dfs = [scrapping_critique_1, scrapping_critique_2, scrapping_critique_3, scrapping_critique_4, scrapping_critique_5, scrapping_critique_6, scrapping_critique_7, scrapping_critique_8, scrapping_critique_9, scrapping_critique_10]\n",
    "\n",
    "df_critiques = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le DataFrame des critiques en CSV\n",
    "df_critiques.to_csv('df_critiques.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_allocine</th>\n",
       "      <th>Note de la critique</th>\n",
       "      <th>Date de publication</th>\n",
       "      <th>Critique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>239331</td>\n",
       "      <td>0,5</td>\n",
       "      <td>Publiée le 5 octobre 2015</td>\n",
       "      <td>\"10.000 days\" est à la base une série créée pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>239331</td>\n",
       "      <td>1,0</td>\n",
       "      <td>Publiée le 12 décembre 2015</td>\n",
       "      <td>Les effets spéciaux bas de gamme mettent les a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>239331</td>\n",
       "      <td>1,0</td>\n",
       "      <td>Publiée le 10 janvier 2017</td>\n",
       "      <td>10,000 somnifères. A peine ça commence qu'un g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>239331</td>\n",
       "      <td>0,5</td>\n",
       "      <td>Publiée le 24 mai 2016</td>\n",
       "      <td>\"10 000 days\" est d'une nullité abyssale. Tout...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>239331</td>\n",
       "      <td>1,5</td>\n",
       "      <td>Publiée le 1 janvier 2017</td>\n",
       "      <td>Beaucoup de parlotes, pas d'action ni d'effets...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801584</th>\n",
       "      <td>146631</td>\n",
       "      <td>2,5</td>\n",
       "      <td>Publiée le 3 septembre 2016</td>\n",
       "      <td>Si vous aimez quand la débilité camoufle la pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801585</th>\n",
       "      <td>146631</td>\n",
       "      <td>2,0</td>\n",
       "      <td>Publiée le 17 mai 2016</td>\n",
       "      <td>La sauce ne prend malheureusement pas. \"Zoolan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801586</th>\n",
       "      <td>146631</td>\n",
       "      <td>0,5</td>\n",
       "      <td>Publiée le 15 juillet 2020</td>\n",
       "      <td>la demi étoiles et pour le casting avec des ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801587</th>\n",
       "      <td>146631</td>\n",
       "      <td>2,5</td>\n",
       "      <td>Publiée le 21 mars 2016</td>\n",
       "      <td>Pas aussi mauvais...Pas très Drôle mais amusan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801588</th>\n",
       "      <td>146631</td>\n",
       "      <td>5,0</td>\n",
       "      <td>Publiée le 13 mai 2016</td>\n",
       "      <td>ma fait halluciner , j'ai trouvé ça trop énorm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>801589 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_allocine Note de la critique          Date de publication  \\\n",
       "0            239331                 0,5    Publiée le 5 octobre 2015   \n",
       "1            239331                 1,0  Publiée le 12 décembre 2015   \n",
       "2            239331                 1,0   Publiée le 10 janvier 2017   \n",
       "3            239331                 0,5       Publiée le 24 mai 2016   \n",
       "4            239331                 1,5    Publiée le 1 janvier 2017   \n",
       "...             ...                 ...                          ...   \n",
       "801584       146631                 2,5  Publiée le 3 septembre 2016   \n",
       "801585       146631                 2,0       Publiée le 17 mai 2016   \n",
       "801586       146631                 0,5   Publiée le 15 juillet 2020   \n",
       "801587       146631                 2,5      Publiée le 21 mars 2016   \n",
       "801588       146631                 5,0       Publiée le 13 mai 2016   \n",
       "\n",
       "                                                 Critique  \n",
       "0       \"10.000 days\" est à la base une série créée pa...  \n",
       "1       Les effets spéciaux bas de gamme mettent les a...  \n",
       "2       10,000 somnifères. A peine ça commence qu'un g...  \n",
       "3       \"10 000 days\" est d'une nullité abyssale. Tout...  \n",
       "4       Beaucoup de parlotes, pas d'action ni d'effets...  \n",
       "...                                                   ...  \n",
       "801584  Si vous aimez quand la débilité camoufle la pe...  \n",
       "801585  La sauce ne prend malheureusement pas. \"Zoolan...  \n",
       "801586  la demi étoiles et pour le casting avec des ac...  \n",
       "801587  Pas aussi mauvais...Pas très Drôle mais amusan...  \n",
       "801588  ma fait halluciner , j'ai trouvé ça trop énorm...  \n",
       "\n",
       "[801589 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_critiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Début NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_critiques = pd.read_csv(\"~/work/df_critiques.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_allocine</th>\n",
       "      <th>Note de la critique</th>\n",
       "      <th>Date de publication</th>\n",
       "      <th>Critique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>239331</td>\n",
       "      <td>0,5</td>\n",
       "      <td>Publiée le 5 octobre 2015</td>\n",
       "      <td>\"10.000 days\" est à la base une série créée pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>239331</td>\n",
       "      <td>1,0</td>\n",
       "      <td>Publiée le 12 décembre 2015</td>\n",
       "      <td>Les effets spéciaux bas de gamme mettent les a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>239331</td>\n",
       "      <td>1,0</td>\n",
       "      <td>Publiée le 10 janvier 2017</td>\n",
       "      <td>10,000 somnifères. A peine ça commence qu'un g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>239331</td>\n",
       "      <td>0,5</td>\n",
       "      <td>Publiée le 24 mai 2016</td>\n",
       "      <td>\"10 000 days\" est d'une nullité abyssale. Tout...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>239331</td>\n",
       "      <td>1,5</td>\n",
       "      <td>Publiée le 1 janvier 2017</td>\n",
       "      <td>Beaucoup de parlotes, pas d'action ni d'effets...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801584</th>\n",
       "      <td>146631</td>\n",
       "      <td>2,5</td>\n",
       "      <td>Publiée le 3 septembre 2016</td>\n",
       "      <td>Si vous aimez quand la débilité camoufle la pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801585</th>\n",
       "      <td>146631</td>\n",
       "      <td>2,0</td>\n",
       "      <td>Publiée le 17 mai 2016</td>\n",
       "      <td>La sauce ne prend malheureusement pas. \"Zoolan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801586</th>\n",
       "      <td>146631</td>\n",
       "      <td>0,5</td>\n",
       "      <td>Publiée le 15 juillet 2020</td>\n",
       "      <td>la demi étoiles et pour le casting avec des ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801587</th>\n",
       "      <td>146631</td>\n",
       "      <td>2,5</td>\n",
       "      <td>Publiée le 21 mars 2016</td>\n",
       "      <td>Pas aussi mauvais...Pas très Drôle mais amusan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801588</th>\n",
       "      <td>146631</td>\n",
       "      <td>5,0</td>\n",
       "      <td>Publiée le 13 mai 2016</td>\n",
       "      <td>ma fait halluciner , j'ai trouvé ça trop énorm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>801589 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_allocine Note de la critique          Date de publication  \\\n",
       "0            239331                 0,5    Publiée le 5 octobre 2015   \n",
       "1            239331                 1,0  Publiée le 12 décembre 2015   \n",
       "2            239331                 1,0   Publiée le 10 janvier 2017   \n",
       "3            239331                 0,5       Publiée le 24 mai 2016   \n",
       "4            239331                 1,5    Publiée le 1 janvier 2017   \n",
       "...             ...                 ...                          ...   \n",
       "801584       146631                 2,5  Publiée le 3 septembre 2016   \n",
       "801585       146631                 2,0       Publiée le 17 mai 2016   \n",
       "801586       146631                 0,5   Publiée le 15 juillet 2020   \n",
       "801587       146631                 2,5      Publiée le 21 mars 2016   \n",
       "801588       146631                 5,0       Publiée le 13 mai 2016   \n",
       "\n",
       "                                                 Critique  \n",
       "0       \"10.000 days\" est à la base une série créée pa...  \n",
       "1       Les effets spéciaux bas de gamme mettent les a...  \n",
       "2       10,000 somnifères. A peine ça commence qu'un g...  \n",
       "3       \"10 000 days\" est d'une nullité abyssale. Tout...  \n",
       "4       Beaucoup de parlotes, pas d'action ni d'effets...  \n",
       "...                                                   ...  \n",
       "801584  Si vous aimez quand la débilité camoufle la pe...  \n",
       "801585  La sauce ne prend malheureusement pas. \"Zoolan...  \n",
       "801586  la demi étoiles et pour le casting avec des ac...  \n",
       "801587  Pas aussi mauvais...Pas très Drôle mais amusan...  \n",
       "801588  ma fait halluciner , j'ai trouvé ça trop énorm...  \n",
       "\n",
       "[801589 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_critiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les notes en float\n",
    "df_critiques['Note_critique_float'] = df_critiques['Note de la critique'].str.replace(',', '.').astype(float)\n",
    "\n",
    "df_critiques['new_date1'] = df_critiques['Date de publication'].str.replace('Publiée le', '').apply(lambda x: ' '.join([french_to_english_month(word) for word in str(x).split()]) if pd.notna(x) else np.nan)\n",
    "\n",
    "\n",
    "\n",
    "# Utiliser dateutil.parser.parse pour convertir les dates en objets datetime\n",
    "df_critiques['new_date'] = df_critiques['new_date1'].apply(lambda x: parser.parse(x, dayfirst=True) if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "colonnes_a_supprimer = [\"new_date1\", \"Date de publication\",'Note de la critique']\n",
    "df_critiques = df_critiques.drop(columns=colonnes_a_supprimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_allocine</th>\n",
       "      <th>Critique</th>\n",
       "      <th>Note_critique_float</th>\n",
       "      <th>new_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>239331</td>\n",
       "      <td>\"10.000 days\" est à la base une série créée pa...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2015-10-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>239331</td>\n",
       "      <td>Les effets spéciaux bas de gamme mettent les a...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-12-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>239331</td>\n",
       "      <td>10,000 somnifères. A peine ça commence qu'un g...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>239331</td>\n",
       "      <td>\"10 000 days\" est d'une nullité abyssale. Tout...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2016-05-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>239331</td>\n",
       "      <td>Beaucoup de parlotes, pas d'action ni d'effets...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801584</th>\n",
       "      <td>146631</td>\n",
       "      <td>Si vous aimez quand la débilité camoufle la pe...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2016-09-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801585</th>\n",
       "      <td>146631</td>\n",
       "      <td>La sauce ne prend malheureusement pas. \"Zoolan...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-05-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801586</th>\n",
       "      <td>146631</td>\n",
       "      <td>la demi étoiles et pour le casting avec des ac...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2020-07-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801587</th>\n",
       "      <td>146631</td>\n",
       "      <td>Pas aussi mauvais...Pas très Drôle mais amusan...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2016-03-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801588</th>\n",
       "      <td>146631</td>\n",
       "      <td>ma fait halluciner , j'ai trouvé ça trop énorm...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-05-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>801589 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_allocine                                           Critique  \\\n",
       "0            239331  \"10.000 days\" est à la base une série créée pa...   \n",
       "1            239331  Les effets spéciaux bas de gamme mettent les a...   \n",
       "2            239331  10,000 somnifères. A peine ça commence qu'un g...   \n",
       "3            239331  \"10 000 days\" est d'une nullité abyssale. Tout...   \n",
       "4            239331  Beaucoup de parlotes, pas d'action ni d'effets...   \n",
       "...             ...                                                ...   \n",
       "801584       146631  Si vous aimez quand la débilité camoufle la pe...   \n",
       "801585       146631  La sauce ne prend malheureusement pas. \"Zoolan...   \n",
       "801586       146631  la demi étoiles et pour le casting avec des ac...   \n",
       "801587       146631  Pas aussi mauvais...Pas très Drôle mais amusan...   \n",
       "801588       146631  ma fait halluciner , j'ai trouvé ça trop énorm...   \n",
       "\n",
       "        Note_critique_float   new_date  \n",
       "0                       0.5 2015-10-05  \n",
       "1                       1.0 2015-12-12  \n",
       "2                       1.0 2017-01-10  \n",
       "3                       0.5 2016-05-24  \n",
       "4                       1.5 2017-01-01  \n",
       "...                     ...        ...  \n",
       "801584                  2.5 2016-09-03  \n",
       "801585                  2.0 2016-05-17  \n",
       "801586                  0.5 2020-07-15  \n",
       "801587                  2.5 2016-03-21  \n",
       "801588                  5.0 2016-05-13  \n",
       "\n",
       "[801589 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_critiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir une polarité à partir des notes des commentaires\n",
    "\n",
    "def find_polarity(note_commentaire):\n",
    "    if float(note_commentaire) <= 2:\n",
    "        return -1 # Négatif\n",
    "    elif float(note_commentaire) >= 4:\n",
    "        return 1 # Positif\n",
    "    else:\n",
    "        return 0 # Neutre\n",
    "\n",
    "    \n",
    "    #elif float(note_commentaire) >= 3.0:\n",
    "    #    return 1 # Positif\n",
    "    #else:\n",
    "    #    return 0 # Neutre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_critiques['Polarité_réelle'] = df_critiques['Note_critique_float'].apply(find_polarity) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "import string\n",
    "\n",
    "def clean_text_french(critique):\n",
    "    # Assurez-vous que la colonne de commentaire est de type chaîne de caractères\n",
    "    critique = critique.astype(str)\n",
    "\n",
    "    # Convertir le texte en minuscules\n",
    "    critique = critique.str.lower()\n",
    "\n",
    "    # Tokenisation des mots\n",
    "    critique = critique.apply(word_tokenize, language='french')\n",
    "\n",
    "    # Supprimer la ponctuation et les caractères spéciaux\n",
    "    critique = critique.apply(lambda tokens: [word for word in tokens if word.isalnum()])\n",
    "\n",
    "    # Supprimer les mots vides\n",
    "    stop_words = set(stopwords.words('french'))\n",
    "    critique = critique.apply(lambda tokens: [word for word in tokens if word not in stop_words])\n",
    "\n",
    "    # Racinisation (stemming)\n",
    "    stemmer = SnowballStemmer('french')\n",
    "    critique = critique.apply(lambda tokens: [stemmer.stem(word) for word in tokens])\n",
    "\n",
    "    # Rejoindre les tokens en une seule chaîne de texte\n",
    "    critique = critique.apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "    return critique\n",
    "\n",
    "# python -m nltk.downloader all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20min, sys: 16.5 s, total: 20min 17s\n",
      "Wall time: 20min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_critiques['Critique_nettoy'] = pd.DataFrame(clean_text_french(df_critiques['Critique']))\n",
    "\n",
    "# CPU times: user 20min, sys: 16.5 s, total: 20min 17s\n",
    "# Wall time: 20min 17s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_allocine</th>\n",
       "      <th>Critique</th>\n",
       "      <th>Note_critique_float</th>\n",
       "      <th>new_date</th>\n",
       "      <th>Critique_nettoy</th>\n",
       "      <th>Polarité_réelle</th>\n",
       "      <th>Text_blob_critique_nettoyé</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>239331</td>\n",
       "      <td>\"10.000 days\" est à la base une série créée pa...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2015-10-05</td>\n",
       "      <td>day bas ser cré eric small réalis film où retr...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>239331</td>\n",
       "      <td>Les effets spéciaux bas de gamme mettent les a...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-12-12</td>\n",
       "      <td>effet spécial bas gamm mettent acteur situat r...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>239331</td>\n",
       "      <td>10,000 somnifères. A peine ça commence qu'un g...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-01-10</td>\n",
       "      <td>somnifer a pein ça commenc gar racont lif pass...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>239331</td>\n",
       "      <td>\"10 000 days\" est d'une nullité abyssale. Tout...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2016-05-24</td>\n",
       "      <td>10 000 day nullit abyssal tout concourt fair s...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>239331</td>\n",
       "      <td>Beaucoup de parlotes, pas d'action ni d'effets...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>beaucoup parlot ni spécial histoir moll tout c...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801584</th>\n",
       "      <td>146631</td>\n",
       "      <td>Si vous aimez quand la débilité camoufle la pe...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2016-09-03</td>\n",
       "      <td>si aim quand débil camoufl pertinent premi zoo...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801585</th>\n",
       "      <td>146631</td>\n",
       "      <td>La sauce ne prend malheureusement pas. \"Zoolan...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-05-17</td>\n",
       "      <td>sauc prend malheur zooland devenu cult temp su...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801586</th>\n",
       "      <td>146631</td>\n",
       "      <td>la demi étoiles et pour le casting avec des ac...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>dem étoil casting acteur fou film a humour tre...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801587</th>\n",
       "      <td>146631</td>\n",
       "      <td>Pas aussi mauvais...Pas très Drôle mais amusan...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2016-03-21</td>\n",
       "      <td>auss mauv tres drôl amus bien film temp temp s...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801588</th>\n",
       "      <td>146631</td>\n",
       "      <td>ma fait halluciner , j'ai trouvé ça trop énorm...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-05-13</td>\n",
       "      <td>fait hallucin trouv ça trop énorm look mod ple...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>801589 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_allocine                                           Critique  \\\n",
       "0            239331  \"10.000 days\" est à la base une série créée pa...   \n",
       "1            239331  Les effets spéciaux bas de gamme mettent les a...   \n",
       "2            239331  10,000 somnifères. A peine ça commence qu'un g...   \n",
       "3            239331  \"10 000 days\" est d'une nullité abyssale. Tout...   \n",
       "4            239331  Beaucoup de parlotes, pas d'action ni d'effets...   \n",
       "...             ...                                                ...   \n",
       "801584       146631  Si vous aimez quand la débilité camoufle la pe...   \n",
       "801585       146631  La sauce ne prend malheureusement pas. \"Zoolan...   \n",
       "801586       146631  la demi étoiles et pour le casting avec des ac...   \n",
       "801587       146631  Pas aussi mauvais...Pas très Drôle mais amusan...   \n",
       "801588       146631  ma fait halluciner , j'ai trouvé ça trop énorm...   \n",
       "\n",
       "        Note_critique_float    new_date  \\\n",
       "0                       0.5  2015-10-05   \n",
       "1                       1.0  2015-12-12   \n",
       "2                       1.0  2017-01-10   \n",
       "3                       0.5  2016-05-24   \n",
       "4                       1.5  2017-01-01   \n",
       "...                     ...         ...   \n",
       "801584                  2.5  2016-09-03   \n",
       "801585                  2.0  2016-05-17   \n",
       "801586                  0.5  2020-07-15   \n",
       "801587                  2.5  2016-03-21   \n",
       "801588                  5.0  2016-05-13   \n",
       "\n",
       "                                          Critique_nettoy  Polarité_réelle  \\\n",
       "0       day bas ser cré eric small réalis film où retr...               -1   \n",
       "1       effet spécial bas gamm mettent acteur situat r...               -1   \n",
       "2       somnifer a pein ça commenc gar racont lif pass...               -1   \n",
       "3       10 000 day nullit abyssal tout concourt fair s...               -1   \n",
       "4       beaucoup parlot ni spécial histoir moll tout c...               -1   \n",
       "...                                                   ...              ...   \n",
       "801584  si aim quand débil camoufl pertinent premi zoo...                0   \n",
       "801585  sauc prend malheur zooland devenu cult temp su...               -1   \n",
       "801586  dem étoil casting acteur fou film a humour tre...               -1   \n",
       "801587  auss mauv tres drôl amus bien film temp temp s...                0   \n",
       "801588  fait hallucin trouv ça trop énorm look mod ple...                1   \n",
       "\n",
       "        Text_blob_critique_nettoyé  \n",
       "0                               -1  \n",
       "1                                1  \n",
       "2                                1  \n",
       "3                                1  \n",
       "4                                1  \n",
       "...                            ...  \n",
       "801584                           1  \n",
       "801585                           1  \n",
       "801586                           0  \n",
       "801587                           1  \n",
       "801588                           1  \n",
       "\n",
       "[801589 rows x 7 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_critiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Blobber\n",
    "from textblob_fr import PatternTagger, PatternAnalyzer\n",
    "tb = Blobber(pos_tagger=PatternTagger(), analyzer=PatternAnalyzer())\n",
    "\n",
    "\n",
    "def attribuer_note(commentaire):\n",
    "    #\n",
    "    vs = tb(commentaire).sentiment[0]\n",
    "    if (vs > 0):\n",
    "        return(1)\n",
    "    elif (vs < 0):\n",
    "        return(-1)\n",
    "    else:\n",
    "        return(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 46s, sys: 188 ms, total: 3min 46s\n",
      "Wall time: 3min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Appliquer la fonction pour attribuer une note à chaque commentaire\n",
    "df_critiques['Text_blob_critique_nettoyé'] = df_critiques['Critique_nettoy'].apply(attribuer_note)\n",
    "\n",
    "# CPU times: user 3min 46s, sys: 188 ms, total: 3min 46s\n",
    "# Wall time: 3min 46s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_critiques.to_csv(\"df_critiques_modif.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_critiques = pd.read_csv(\"df_critiques_modif.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On supprimer les lignes avec une polarité neutre\n",
    "df_critiques = df_critiques[df_critiques['Polarité_réelle'] != 0]\n",
    "\n",
    "# O\n",
    "length_limit = 3000\n",
    "df_critiques = df_critiques[df_critiques['Critique'].str.len() <= length_limit]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_critiques.loc[df_critiques['Polarité_réelle'] == -1, 'Polarité_réelle'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_critiques = df_critiques.dropna(subset=['Critique_nettoy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Polarité_réelle\n",
       "0    189541\n",
       "1    327120\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_critiques.groupby('Polarité_réelle').size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_critiques = df_critiques[df_critiques['Critique'].str.len() > 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_critiques1, df_critiques2 = train_test_split(df_critiques, test_size=0.5, random_state=42)\n",
    "\n",
    "# Séparez les commentaires positifs et négatifs\n",
    "positifs = df_critiques1[df_critiques1['Polarité_réelle'] == 1]\n",
    "negatifs = df_critiques1[df_critiques1['Polarité_réelle'] == 0]\n",
    "\n",
    "# Divisez chaque ensemble en ensembles d'entraînement et de test\n",
    "train_positifs, test_positifs = train_test_split(positifs, test_size=0.2, random_state=42)\n",
    "train_negatifs, test_negatifs = train_test_split(negatifs, test_size=0.2, random_state=42)\n",
    "\n",
    "# Concaténez les ensembles d'entraînement et de test pour obtenir les ensembles finaux\n",
    "train_set = pd.concat([train_positifs, train_negatifs], axis=0)\n",
    "test_set = pd.concat([test_positifs, test_negatifs], axis=0)\n",
    "\n",
    "# Mélangez les ensembles (optionnel)\n",
    "train_set = train_set.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "test_set = test_set.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_set, y_test_set, X_train_set, y_train_set =  test_set, test_set['Polarité_réelle'], train_set, train_set['Polarité_réelle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xf = pd.concat([X_train_set, X_test_set])\n",
    "yf = pd.concat([y_train_set, y_test_set])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(Xf['Critique_nettoy'])\n",
    "\n",
    "Xf_onehot = cv.transform(Xf['Critique_nettoy'])\n",
    "Xtest_onehot = cv.transform(X_test_set['Critique_nettoy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>84304</th>\n",
       "      <th>84305</th>\n",
       "      <th>84306</th>\n",
       "      <th>84307</th>\n",
       "      <th>84308</th>\n",
       "      <th>84309</th>\n",
       "      <th>84310</th>\n",
       "      <th>84311</th>\n",
       "      <th>84312</th>\n",
       "      <th>84313</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258325</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258326</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258327</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258328</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258329</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258330 rows × 84314 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1      2      3      4      5      6      7      8      9      \\\n",
       "0           0      0      0      0      0      0      0      0      0      0   \n",
       "1           0      0      0      0      0      0      0      0      0      0   \n",
       "2           0      0      0      0      0      0      0      0      0      0   \n",
       "3           0      0      0      0      0      0      0      0      0      0   \n",
       "4           0      0      0      0      0      0      0      0      0      0   \n",
       "...       ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "258325      0      0      0      0      0      0      0      0      0      0   \n",
       "258326      0      0      0      0      0      0      0      0      0      0   \n",
       "258327      0      0      0      0      0      0      0      0      0      0   \n",
       "258328      0      0      0      0      0      0      0      0      0      0   \n",
       "258329      0      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "        ...  84304  84305  84306  84307  84308  84309  84310  84311  84312  \\\n",
       "0       ...      0      0      0      0      0      0      0      0      0   \n",
       "1       ...      0      0      0      0      0      0      0      0      0   \n",
       "2       ...      0      0      0      0      0      0      0      0      0   \n",
       "3       ...      0      0      0      0      0      0      0      0      0   \n",
       "4       ...      0      0      0      0      0      0      0      0      0   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "258325  ...      0      0      0      0      0      0      0      0      0   \n",
       "258326  ...      0      0      0      0      0      0      0      0      0   \n",
       "258327  ...      0      0      0      0      0      0      0      0      0   \n",
       "258328  ...      0      0      0      0      0      0      0      0      0   \n",
       "258329  ...      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "        84313  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "258325      0  \n",
       "258326      0  \n",
       "258327      0  \n",
       "258328      0  \n",
       "258329      0  \n",
       "\n",
       "[258330 rows x 84314 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Xf_onehot.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.5, max_iter=1000000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.5, max_iter=1000000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.5, max_iter=1000000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model_logReg = LogisticRegression(C=0.5, max_iter=1000000)\n",
    "model_logReg.fit(Xf_onehot, yf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17394  1603]\n",
      " [  971 31698]]\n"
     ]
    }
   ],
   "source": [
    "pred_logReg = model_logReg.predict(Xtest_onehot)\n",
    "cm_logReg = confusion_matrix(y_test_set, pred_logReg)\n",
    "print(cm)\n",
    "print (\"Précision: %s\" % accuracy_score(y_test_set, pred_logReg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes on Count Vectors\n",
    "from sklearn import model_selection, preprocessing, naive_bayes, metrics\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "model_MultinomialNB= naive_bayes.MultinomialNB()\n",
    "model_MultinomialNB.fit(Xf_onehot, yf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17085  1912]\n",
      " [ 1909 30760]]\n",
      "Précision: 0.9260442070220261\n"
     ]
    }
   ],
   "source": [
    "# Testing model performance\n",
    "pred_MultinomialNB= model_MultinomialNB.predict(Xtest_onehot)\n",
    "cm_MultinomialNB = confusion_matrix(y_test_set, pred_MultinomialNB)\n",
    "print(cm_MultinomialNB)\n",
    "print (\"Précision: %s\" % accuracy_score(y_test_set, pred_MultinomialNB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = ensemble.RandomForestClassifier()\n",
    "model_rf.fit(Xf_onehot, yf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ref = model_rf.predict(Xtest_onehot)\n",
    "cm_rf = confusion_matrix(y_test_set, pred_ref)\n",
    "print(cm_rf)\n",
    "print (\"Précision: %s\" % accuracy_score(y_test_set, pred_ref))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
